{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30d4470-b13e-4762-ad9e-71af13ef42cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "class VideoProcessor:\n",
    "    def __init__(self, video_path, frame_rate=30):\n",
    "        self.video_path = video_path\n",
    "        self.frame_rate = frame_rate\n",
    "        self.frames = self.extract_frames()\n",
    "\n",
    "    def extract_frames(self):\n",
    "        cap = cv2.VideoCapture(self.video_path)\n",
    "        frames = []\n",
    "        fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "        frame_interval = int(fps / self.frame_rate)\n",
    "        count = 0\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            if count % frame_interval == 0:\n",
    "                frames.append(frame)\n",
    "            count += 1\n",
    "        cap.release()\n",
    "        return frames\n",
    "\n",
    "    def preprocess_frame(self, frame, target_size):\n",
    "        resized_frame = cv2.resize(frame, target_size)\n",
    "        normalized_frame = resized_frame / 255.0\n",
    "        return normalized_frame\n",
    "\n",
    "    def preprocess_frames(self, target_size):\n",
    "        return [self.preprocess_frame(frame, target_size) for frame in self.frames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3562e45-3baf-4735-b17b-0b7812b1002a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class DenseBlock3D(nn.Module):\n",
    "    def __init__(self, in_channels, growth_rate, num_layers):\n",
    "        super(DenseBlock3D, self).__init__()\n",
    "        self.layers = nn.ModuleList()\n",
    "        for i in range(num_layers):\n",
    "            self.layers.append(self._make_layer(in_channels + i * growth_rate, growth_rate))\n",
    "\n",
    "    def _make_layer(self, in_channels, growth_rate):\n",
    "        layer = nn.Sequential(\n",
    "            nn.Conv3d(in_channels, growth_rate, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm3d(growth_rate),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        return layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = [x]\n",
    "        for layer in self.layers:\n",
    "            out = layer(torch.cat(features, 1))\n",
    "            features.append(out)\n",
    "        return torch.cat(features, 1)\n",
    "\n",
    "class InceptionModule3D(nn.Module):\n",
    "    def __init__(self, in_channels, out1x1, out3x3red, out3x3, out5x5red, out5x5, out_pool):\n",
    "        super(InceptionModule3D, self).__init__()\n",
    "        self.branch1 = nn.Sequential(\n",
    "            nn.Conv3d(in_channels, out1x1, kernel_size=1),\n",
    "            nn.BatchNorm3d(out1x1),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        self.branch2 = nn.Sequential(\n",
    "            nn.Conv3d(in_channels, out3x3red, kernel_size=1),\n",
    "            nn.BatchNorm3d(out3x3red),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv3d(out3x3red, out3x3, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm3d(out3x3),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        self.branch3 = nn.Sequential(\n",
    "            nn.Conv3d(in_channels, out5x5red, kernel_size=1),\n",
    "            nn.BatchNorm3d(out5x5red),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv3d(out5x5red, out5x5, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm3d(out5x5),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        self.branch4 = nn.Sequential(\n",
    "            nn.MaxPool3d(kernel_size=3, stride=1, padding=1),\n",
    "            nn.Conv3d(in_channels, out_pool, kernel_size=1),\n",
    "            nn.BatchNorm3d(out_pool),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        branch1 = self.branch1(x)\n",
    "        branch2 = self.branch2(x)\n",
    "        branch3 = self.branch3(x)\n",
    "        branch4 = self.branch4(x)\n",
    "        return torch.cat([branch1, branch2, branch3, branch4], 1)\n",
    "\n",
    "class SELayer3D(nn.Module):\n",
    "    def __init__(self, channel, reduction=16):\n",
    "        super(SELayer3D, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool3d(1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(channel, channel // reduction, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(channel // reduction, channel, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, _, _, _ = x.size()\n",
    "        y = self.avg_pool(x).view(b, c)\n",
    "        y = self.fc(y).view(b, c, 1, 1, 1)\n",
    "        return x * y.expand_as(x)\n",
    "\n",
    "class Attention3D(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=1):\n",
    "        super(Attention3D, self).__init__()\n",
    "        self.conv1 = nn.Conv3d(in_channels, out_channels, kernel_size=1)\n",
    "        self.conv2 = nn.Conv3d(out_channels, out_channels, kernel_size=kernel_size, padding=kernel_size//2)\n",
    "        self.conv3 = nn.Conv3d(out_channels, in_channels, kernel_size=1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        attention = self.conv1(x)\n",
    "        attention = self.conv2(attention)\n",
    "        attention = self.conv3(attention)\n",
    "        attention = self.sigmoid(attention)\n",
    "        return x * attention\n",
    "\n",
    "class Advanced3DCNN(nn.Module):\n",
    "    def __init__(self, num_classes, growth_rate=12, num_layers=4, reduction=16):\n",
    "        super(Advanced3DCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv3d(1, growth_rate * 2, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm3d(growth_rate * 2)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.pool = nn.MaxPool3d(kernel_size=2, stride=2, padding=0)\n",
    "        \n",
    "        # DenseBlock\n",
    "        self.dense_block = DenseBlock3D(growth_rate * 2, growth_rate, num_layers)\n",
    "        self.transition = self._make_transition(growth_rate * (2 + num_layers), growth_rate * 2)\n",
    "        \n",
    "        # Inception\n",
    "        self.inception = InceptionModule3D(growth_rate * 2, 64, 96, 128, 16, 32, 32)\n",
    "        \n",
    "        # SE Layer\n",
    "        self.se = SELayer3D(growth_rate * 2)\n",
    "        \n",
    "        # Attention\n",
    "        self.attention = Attention3D(growth_rate * 2, growth_rate)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(growth_rate * 2 * 4 * 4 * 4, 512)\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "\n",
    "    def _make_transition(self, in_channels, out_channels):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv3d(in_channels, out_channels, kernel_size=1, stride=1, padding=0),\n",
    "            nn.BatchNorm3d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool3d(kernel_size=2, stride=2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)\n",
    "        \n",
    "        x = self.dense_block(x)\n",
    "        x = self.transition(x)\n",
    "        \n",
    "        x = self.inception(x)\n",
    "        \n",
    "        x = self.se(x)\n",
    "        \n",
    "        x = self.attention(x)\n",
    "        \n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "# Function to plot metrics\n",
    "def plot_metrics(train_losses, val_losses, test_loss, val_accuracies, test_accuracy):\n",
    "    epochs = range(1, len(train_losses) + 1)\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.plot(epochs, train_losses, label='Training Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(2, 2, 2)\n",
    "    plt.plot(epochs, val_losses, label='Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Validation Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(2, 2, 3)\n",
    "    plt.plot(epochs, val_accuracies, label='Validation Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Validation Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(2, 2, 4)\n",
    "    plt.bar(['Test'], [test_loss], label='Test Loss')\n",
    "    plt.bar(['Test'], [test_accuracy], label='Test Accuracy')\n",
    "    plt.xlabel('Metrics')\n",
    "    plt.ylabel('Values')\n",
    "    plt.title('Test Metrics')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def train(model, trainloader, validloader, testloader, epochs=10, learning_rate=0.001, weight_decay=0.01):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    val_accuracies = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in trainloader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        train_losses.append(running_loss / len(trainloader))\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in validloader:\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "        val_losses.append(val_loss / len(validloader))\n",
    "        val_accuracies.append(100 * correct / total)\n",
    "\n",
    "        print(f'Epoch {epoch + 1}/{epochs}, Training Loss: {train_losses[-1]}, Validation Loss: {val_losses[-1]}, Validation Accuracy: {val_accuracies[-1]}%')\n",
    "\n",
    "    # Testing\n",
    "    test_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in testloader:\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    test_loss /= len(testloader)\n",
    "    test_accuracy = 100 * correct / total\n",
    "\n",
    "    print(f'Test Loss: {test_loss}, Test Accuracy: {test_accuracy}%')\n",
    "\n",
    "    plot_metrics(train_losses, val_losses, test_loss, val_accuracies, test_accuracy)\n",
    "\n",
    "# Assuming trainloader, validloader, and testloader are defined\n",
    "model = Advanced3DCNN(num_classes=10)\n",
    "train(model, trainloader, validloader, testloader, epochs=10, learning_rate=0.001, weight_decay=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877584d2-b124-410a-96ac-38b0e6e68e1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8770c8e7-dc84-4707-8898-5635ab362018",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9446b66b-d63f-46f4-bcb2-21d4743b33f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6227776d-d58f-4d3f-bed7-8c8428a7c85f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80d7b10-05f8-4c8a-9025-424ad292e910",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class DenseBlock3D:\n",
    "    def __init__(self, in_channels, growth_rate, num_layers):\n",
    "        self.in_channels = in_channels\n",
    "        self.growth_rate = growth_rate\n",
    "        self.num_layers = num_layers\n",
    "        self.weights = [self._initialize_weights(in_channels + i * growth_rate, growth_rate) for i in range(num_layers)]\n",
    "\n",
    "    def _initialize_weights(self, in_channels, out_channels):\n",
    "        return np.random.randn(3, 3, 3, in_channels, out_channels) * np.sqrt(2.0 / (in_channels * out_channels))\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = [x]\n",
    "        for weights in self.weights:\n",
    "            out = self._convolve3d(np.concatenate(features, axis=-1), weights)\n",
    "            out = self._relu(out)\n",
    "            features.append(out)\n",
    "        return np.concatenate(features, axis=-1)\n",
    "\n",
    "    def _convolve3d(self, x, weights):\n",
    "        output_shape = (\n",
    "            x.shape[0] - weights.shape[0] + 1,\n",
    "            x.shape[1] - weights.shape[1] + 1,\n",
    "            x.shape[2] - weights.shape[2] + 1,\n",
    "            weights.shape[-1]\n",
    "        )\n",
    "        output = np.zeros(output_shape)\n",
    "        for k in range(weights.shape[-1]):\n",
    "            for i in range(output_shape[0]):\n",
    "                for j in range(output_shape[1]):\n",
    "                    for l in range(output_shape[2]):\n",
    "                        region = x[i:i + weights.shape[0], j:j + weights.shape[1], l:l + weights.shape[2], :]\n",
    "                        output[i, j, l, k] = np.sum(region * weights[..., k])\n",
    "        return output\n",
    "\n",
    "    def _relu(self, x):\n",
    "        return np.maximum(0, x)\n",
    "\n",
    "class InceptionModule3D:\n",
    "    def __init__(self, in_channels, out1x1, out3x3red, out3x3, out5x5red, out5x5, out_pool):\n",
    "        self.branch1_weights = self._initialize_weights(in_channels, out1x1)\n",
    "        self.branch2_weights1 = self._initialize_weights(in_channels, out3x3red)\n",
    "        self.branch2_weights2 = self._initialize_weights(out3x3red, out3x3)\n",
    "        self.branch3_weights1 = self._initialize_weights(in_channels, out5x5red)\n",
    "        self.branch3_weights2 = self._initialize_weights(out5x5red, out5x5)\n",
    "        self.branch4_weights = self._initialize_weights(in_channels, out_pool)\n",
    "\n",
    "    def _initialize_weights(self, in_channels, out_channels):\n",
    "        return np.random.randn(3, 3, 3, in_channels, out_channels) * np.sqrt(2.0 / (in_channels * out_channels))\n",
    "\n",
    "    def forward(self, x):\n",
    "        branch1 = self._relu(self._convolve3d(x, self.branch1_weights))\n",
    "        branch2 = self._relu(self._convolve3d(self._relu(self._convolve3d(x, self.branch2_weights1)), self.branch2_weights2))\n",
    "        branch3 = self._relu(self._convolve3d(self._relu(self._convolve3d(x, self.branch3_weights1)), self.branch3_weights2))\n",
    "        branch4 = self._maxpool3d(x)\n",
    "        branch4 = self._relu(self._convolve3d(branch4, self.branch4_weights))\n",
    "        return np.concatenate([branch1, branch2, branch3, branch4], axis=-1)\n",
    "\n",
    "    def _convolve3d(self, x, weights):\n",
    "        output_shape = (\n",
    "            x.shape[0] - weights.shape[0] + 1,\n",
    "            x.shape[1] - weights.shape[1] + 1,\n",
    "            x.shape[2] - weights.shape[2] + 1,\n",
    "            weights.shape[-1]\n",
    "        )\n",
    "        output = np.zeros(output_shape)\n",
    "        for k in range(weights.shape[-1]):\n",
    "            for i in range(output_shape[0]):\n",
    "                for j in range(output_shape[1]):\n",
    "                    for l in range(output_shape[2]):\n",
    "                        region = x[i:i + weights.shape[0], j:j + weights.shape[1], l:l + weights.shape[2], :]\n",
    "                        output[i, j, l, k] = np.sum(region * weights[..., k])\n",
    "        return output\n",
    "\n",
    "    def _maxpool3d(self, x, size=3, stride=1):\n",
    "        output_shape = (\n",
    "            (x.shape[0] - size) // stride + 1,\n",
    "            (x.shape[1] - size) // stride + 1,\n",
    "            (x.shape[2] - size) // stride + 1,\n",
    "            x.shape[3]\n",
    "        )\n",
    "        output = np.zeros(output_shape)\n",
    "        for i in range(0, x.shape[0] - size + 1, stride):\n",
    "            for j in range(0, x.shape[1] - size + 1, stride):\n",
    "                for l in range(0, x.shape[2] - size + 1, stride):\n",
    "                    output[i // stride, j // stride, l // stride, :] = np.max(x[i:i + size, j:j + size, l:l + size, :], axis=(0, 1, 2))\n",
    "        return output\n",
    "\n",
    "    def _relu(self, x):\n",
    "        return np.maximum(0, x)\n",
    "\n",
    "class SELayer3D:\n",
    "    def __init__(self, channel, reduction=16):\n",
    "        self.fc1_weights = self._initialize_weights(channel, channel // reduction)\n",
    "        self.fc2_weights = self._initialize_weights(channel // reduction, channel)\n",
    "\n",
    "    def _initialize_weights(self, in_channels, out_channels):\n",
    "        return np.random.randn(in_channels, out_channels) * np.sqrt(2.0 / (in_channels * out_channels))\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, _, _, _ = x.shape\n",
    "        y = np.mean(x, axis=(2, 3, 4), keepdims=True)\n",
    "        y = np.dot(y.reshape(b, c), self.fc1_weights)\n",
    "        y = self._relu(y)\n",
    "        y = np.dot(y, self.fc2_weights)\n",
    "        y = self._sigmoid(y).reshape(b, c, 1, 1, 1)\n",
    "        return x * y\n",
    "\n",
    "    def _relu(self, x):\n",
    "        return np.maximum(0, x)\n",
    "\n",
    "    def _sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "class Attention3D:\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=1):\n",
    "        self.conv1_weights = self._initialize_weights(in_channels, out_channels, kernel_size)\n",
    "        self.conv2_weights = self._initialize_weights(out_channels, out_channels, kernel_size)\n",
    "        self.conv3_weights = self._initialize_weights(out_channels, in_channels, kernel_size)\n",
    "        self.sigmoid = np.vectorize(lambda x: 1 / (1 + np.exp(-x)))\n",
    "\n",
    "    def _initialize_weights(self, in_channels, out_channels, kernel_size):\n",
    "        return np.random.randn(kernel_size, kernel_size, kernel_size, in_channels, out_channels) * np.sqrt(2.0 / (in_channels * out_channels))\n",
    "\n",
    "    def forward(self, x):\n",
    "        attention = self._convolve3d(x, self.conv1_weights)\n",
    "        attention = self._convolve3d(attention, self.conv2_weights)\n",
    "        attention = self._convolve3d(attention, self.conv3_weights)\n",
    "        attention = self.sigmoid(attention)\n",
    "        return x * attention\n",
    "\n",
    "    def _convolve3d(self, x, weights):\n",
    "        output_shape = (\n",
    "            x.shape[0] - weights.shape[0] + 1,\n",
    "            x.shape[1] - weights.shape[1] + 1,\n",
    "            x.shape[2] - weights.shape[2] + 1,\n",
    "            weights.shape[-1]\n",
    "        )\n",
    "        output = np.zeros(output_shape)\n",
    "        for k in range(weights.shape[-1]):\n",
    "            for i in range(output_shape[0]):\n",
    "                for j in range(output_shape[1]):\n",
    "                    for l in range(output_shape[2]):\n",
    "                        region = x[i:i + weights.shape[0], j:j + weights.shape[1], l:l + weights.shape[2], :]\n",
    "                        output[i, j, l, k] = np.sum(region * weights[..., k])\n",
    "        return output\n",
    "\n",
    "class Advanced3DCNN:\n",
    "    def __init__(self, num_classes, growth_rate=12, num_layers=4, reduction=16):\n",
    "        self.num_classes = num_classes\n",
    "        self.conv1_weights = self._initialize_weights(1, growth_rate * 2)\n",
    "        self.dense_block = DenseBlock3D(growth_rate * 2, growth_rate, num_layers)\n",
    "        self.transition_weights = self._initialize_weights(growth_rate * (2 + num_layers), growth_rate * 2)\n",
    "        self.inception = InceptionModule3D(growth_rate * 2, 64, 96, 128, 16, 32, 32)\n",
    "        self.se = SELayer3D(growth_rate * 2, reduction)\n",
    "        self.attention = Attention3D(growth_rate * 2, growth_rate)\n",
    "        self.fc1_weights = self._initialize_weights(growth_rate * 2 * 4 * 4 * 4, 512)\n",
    "        self.fc2_weights = self._initialize_weights(512, num_classes)\n",
    "\n",
    "    def _initialize_weights(self, in_channels, out_channels):\n",
    "        return np.random.randn(3, 3, 3, in_channels, out_channels) * np.sqrt(2.0 / (in_channels * out_channels))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self._convolve3d(x, self.conv1_weights)\n",
    "        x = self._relu(x)\n",
    "        x = self._maxpool3d(x)\n",
    "        \n",
    "        x = self.dense_block.forward(x)\n",
    "        x = self._convolve3d(x, self.transition_weights)\n",
    "        x = self._relu(x)\n",
    "        x = self._maxpool3d(x)\n",
    "        \n",
    "        x = self.inception.forward(x)\n",
    "        \n",
    "        x = self.se.forward(x)\n",
    "        \n",
    "        x = self.attention.forward(x)\n",
    "        \n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        x = np.dot(x, self.fc1_weights.reshape(-1, 512))\n",
    "        x = self._relu(x)\n",
    "        x = np.dot(x, self.fc2_weights)\n",
    "        return x\n",
    "\n",
    "    def _convolve3d(self, x, weights):\n",
    "        output_shape = (\n",
    "            x.shape[0] - weights.shape[0] + 1,\n",
    "            x.shape[1] - weights.shape[1] + 1,\n",
    "            x.shape[2] - weights.shape[2] + 1,\n",
    "            weights.shape[-1]\n",
    "        )\n",
    "        output = np.zeros(output_shape)\n",
    "        for k in range(weights.shape[-1]):\n",
    "            for i in range(output_shape[0]):\n",
    "                for j in range(output_shape[1]):\n",
    "                    for l in range(output_shape[2]):\n",
    "                        region = x[i:i + weights.shape[0], j:j + weights.shape[1], l:l + weights.shape[2], :]\n",
    "                        output[i, j, l, k] = np.sum(region * weights[..., k])\n",
    "        return output\n",
    "\n",
    "    def _relu(self, x):\n",
    "        return np.maximum(0, x)\n",
    "\n",
    "    def _maxpool3d(self, x, size=2, stride=2):\n",
    "        output_shape = (\n",
    "            (x.shape[0] - size) // stride + 1,\n",
    "            (x.shape[1] - size) // stride + 1,\n",
    "            (x.shape[2] - size) // stride + 1,\n",
    "            x.shape[3]\n",
    "        )\n",
    "        output = np.zeros(output_shape)\n",
    "        for i in range(0, x.shape[0] - size + 1, stride):\n",
    "            for j in range(0, x.shape[1] - size + 1, stride):\n",
    "                for l in range(0, x.shape[2] - size + 1, stride):\n",
    "                    output[i // stride, j // stride, l // stride, :] = np.max(x[i:i + size, j:j + size, l:l + size, :], axis=(0, 1, 2))\n",
    "        return output\n",
    "\n",
    "def plot_metrics(train_losses, val_losses, test_loss, val_accuracies, test_accuracy):\n",
    "    epochs = range(1, len(train_losses) + 1)\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.plot(epochs, train_losses, label='Training Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(2, 2, 2)\n",
    "    plt.plot(epochs, val_losses, label='Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Validation Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(2, 2, 3)\n",
    "    plt.plot(epochs, val_accuracies, label='Validation Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Validation Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(2, 2, 4)\n",
    "    plt.bar(['Test'], [test_loss], label='Test Loss')\n",
    "    plt.bar(['Test'], [test_accuracy], label='Test Accuracy')\n",
    "    plt.xlabel('Metrics')\n",
    "    plt.ylabel('Values')\n",
    "    plt.title('Test Metrics')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def cross_entropy_loss(predictions, targets):\n",
    "    return -np.sum(targets * np.log(predictions))\n",
    "\n",
    "def accuracy(predictions, targets):\n",
    "    pred_labels = np.argmax(predictions, axis=1)\n",
    "    true_labels = np.argmax(targets, axis=1)\n",
    "    return np.mean(pred_labels == true_labels)\n",
    "\n",
    "def train(model, train_data, train_labels, val_data, val_labels, test_data, test_labels, epochs=10, batch_size=32, learning_rate=0.001, weight_decay=0.01):\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    val_accuracies = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        permutation = np.random.permutation(len(train_data))\n",
    "        train_data = train_data[permutation]\n",
    "        train_labels = train_labels[permutation]\n",
    "        epoch_loss = 0\n",
    "        for i in range(0, len(train_data), batch_size):\n",
    "            batch_data = train_data[i:i + batch_size]\n",
    "            batch_labels = train_labels[i:i + batch_size]\n",
    "            predictions = model.forward(batch_data)\n",
    "            loss = cross_entropy_loss(predictions, batch_labels) + (weight_decay / 2) * np.sum([np.sum(layer.weights**2) for layer in model.dense_block.layers])\n",
    "            epoch_loss += loss\n",
    "            # Backward pass and update\n",
    "            model.backward(batch_data, batch_labels, learning_rate, weight_decay)\n",
    "        \n",
    "        train_losses.append(epoch_loss / len(train_data))\n",
    "\n",
    "        # Validation\n",
    "        val_predictions = model.forward(val_data)\n",
    "        val_loss = cross_entropy_loss(val_predictions, val_labels)\n",
    "        val_accuracy = accuracy(val_predictions, val_labels)\n",
    "        val_losses.append(val_loss / len(val_data))\n",
    "        val_accuracies.append(val_accuracy)\n",
    "\n",
    "        print(f'Epoch {epoch + 1}/{epochs}, Training Loss: {train_losses[-1]}, Validation Loss: {val_losses[-1]}, Validation Accuracy: {val_accuracies[-1]}')\n",
    "\n",
    "    # Testing\n",
    "    test_predictions = model.forward(test_data)\n",
    "    test_loss = cross_entropy_loss(test_predictions, test_labels)\n",
    "    test_accuracy = accuracy(test_predictions, test_labels)\n",
    "\n",
    "    print(f'Test Loss: {test_loss / len(test_data)}, Test Accuracy: {test_accuracy}')\n",
    "\n",
    "    plot_metrics(train_losses, val_losses, test_loss / len(test_data), val_accuracies, test_accuracy)\n",
    "\n",
    "# Assuming you have train_data, train_labels, val_data, val_labels, test_data, test_labels prepared\n",
    "# Initialize the model\n",
    "model = Advanced3DCNN(num_classes=10)\n",
    "\n",
    "# Train the model\n",
    "train(model, train_data, train_labels, val_data, val_labels, test_data, test_labels, epochs=10, batch_size=32, learning_rate=0.001, weight_decay=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186edd2e-349f-4ad3-a98e-2c13403220bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
